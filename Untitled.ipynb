{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "# Include Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import tensorflow.contrib.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed forward network (multi-layer-perceptron, or mlp)\n",
    "\n",
    "def build_mlp(mlp_input,output_size,scope,n_layers,size,output_activation=None):\n",
    "    '''\n",
    "    Build a feed forward network\n",
    "    '''\n",
    "    Input = mlp_input\n",
    "    with tf.variable_scope(scope):\n",
    "        # Dense Layers\n",
    "        for i in range(n_layers-1):\n",
    "            dense = tf.layers.dense(inputs = Input, units = output_size, activation = tf.nn.relu, bias_initializer=tf.constant_initializer(1.0))\n",
    "            Input = dense\n",
    "        # Fully Connected Layer\n",
    "        out = layers.fully_connected(inputs = Input, num_outputs = output_size, activation_fn=output_activation)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
    "observation_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n if discrete else env.action_space.shape[0]\n",
    "max_ep_len = 10\n",
    "num_traj = 100\n",
    "traj_length = max_ep_len*(observation_dim + 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds the initial policy\n",
    "def build_policy_explore(observation_placeholder,action_placeholder,action_dim, scope = \"policy_explore\"):\n",
    "    if (discrete):\n",
    "        action_logits = build_mlp(observation_placeholder,action_dim,scope = scope,n_layers=3,size = 60,output_activation=None)\n",
    "        sampled_action = tf.multinomial(action_logits,1)\n",
    "        sampled_action = tf.squeeze(sampled_action, axis=1)\n",
    "        logprob = -tf.nn.sparse_softmax_cross_entropy_with_logits(logits = action_logits, labels = action_placeholder)\n",
    "\n",
    "    else:   \n",
    "        action_means = build_mlp(observation_placeholder,action_dim,scope,n_layers=3,size = 60,output_activation=None)\n",
    "        init = tf.constant(np.random.rand(1, 2))\n",
    "        log_std = tf.get_variable(\"log_std\", [action_dim])\n",
    "        ampled_action =   action_means + tf.multiply(tf.exp(log_std),tf.random_normal(shape = (action_dim,1),mean=0,stddev=1))\n",
    "        mvn = tf.contrib.distributions.MultivariateNormalDiag(action_means, tf.exp(log_std))\n",
    "        logprob =  mvn.log_prob(value = action_placeholder, name='log_prob')\n",
    "        \n",
    "    return sampled_action, logprob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(encoder_input_placeholder, scope = \"encoder\"):\n",
    "    #output = build_mlp(encoder_input_placeholder,latent_1_dim,scope = scope,n_layers=3 ,size = 60,output_activation=None)\n",
    "    #TODO\n",
    "    #output = encoder_input_placeholder\n",
    "    Z = build_mlp(encoder_input_placeholder,6,scope = scope,n_layers=3,size = 60,output_activation=None)\n",
    "    \n",
    "    return tf.reshape(tf.reduce_mean(Z, axis=0),(1,6))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decoder1(decoder_input_placeholder,d1_out_dim, scope = \"decoder_A\"):\n",
    "        d1 = build_mlp(decoder_input_placeholder,d1_out_dim,scope = scope,n_layers=3,size = 60,output_activation=None)\n",
    "        #d2 = build_mlp(decoder_input_placeholder,d2_out_dim,scope = scope,n_layers=3,size = 60,output_activation=None)\n",
    "        #d3 = build_mlp(decoder_input_placeholder,d3_out_dim,scope = scope,n_layers=3,size = 60,output_activation=None)\n",
    "\n",
    "        return d1\n",
    "def Decoder2(decoder_input_placeholder, d2_out_dim, scope = \"decoder_B\"):\n",
    "        #d1 = build_mlp(decoder_input_placeholder,d1_out_dim,scope = scope,n_layers=3,size = 60,output_activation=None)\n",
    "        d2 = build_mlp(decoder_input_placeholder,d2_out_dim,scope = scope,n_layers=3,size = 60,output_activation=None)\n",
    "        #d3 = build_mlp(decoder_input_placeholder,d3_out_dim,scope = scope,n_layers=3,size = 60,output_activation=None)\n",
    "\n",
    "        return d2\n",
    "def Decoder3(decoder_input_placeholder,d3_out_dim, scope = \"decoder_C\"):\n",
    "        #d1 = build_mlp(decoder_input_placeholder,d1_out_dim,scope = scope,n_layers=3,size = 60,output_activation=None)\n",
    "        #d2 = build_mlp(decoder_input_placeholder,d2_out_dim,scope = scope,n_layers=3,size = 60,output_activation=None)\n",
    "        d3 = build_mlp(decoder_input_placeholder,d3_out_dim,scope = scope,n_layers=3,size = 60,output_activation=None)\n",
    "\n",
    "        return d3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_policy_exploit(Input_placeholder, d1_PH, d2_PH, d3_PH,action_dim,scope = \"policy_explore\"):\n",
    "    d1_PH = tf.reshape(d1_PH, [observation_dim, traj_length])\n",
    "    d2_PH = tf.reshape(d2_PH, [traj_length, traj_length])\n",
    "    d3_PH = tf.reshape(d3_PH, [traj_length, action_dim])\n",
    "    if (discrete):\n",
    "        action_logits = tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(Input_placeholder,d1_PH)), d2_PH)),d3_PH))\n",
    "        \n",
    "        sampled_action = tf.multinomial(action_logits,1)\n",
    "        sampled_action = tf.squeeze(sampled_action, axis=1)\n",
    "        logprob = -tf.nn.sparse_softmax_cross_entropy_with_logits(logits = action_logits, labels = action_placeholder)\n",
    "\n",
    "    else:   \n",
    "        action_means = tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(Input_placeholder,d1_PH)), d2_PH)),d3_PH))\n",
    "        init = tf.constant(np.random.rand(1, 2))\n",
    "        log_std = tf.get_variable(\"log_std\", [action_dim])\n",
    "        ampled_action =   action_means + tf.multiply(tf.exp(log_std),tf.random_normal(shape = (action_dim,1),mean=0,stddev=1))\n",
    "        mvn = tf.contrib.distributions.MultivariateNormalDiag(action_means, tf.exp(log_std))\n",
    "        logprob =  mvn.log_prob(value = action_placeholder, name='log_prob')\n",
    "        \n",
    "    return sampled_action, logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline and Advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_advantage(returns, observations):\n",
    "    #baseline = self.sess.run(baseline, {input_placeholder:observations})\n",
    "    adv = returns - baseline\n",
    "    adv = (adv - np.mean(adv))/np.std(adv)\n",
    "    return adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_baseline(returns, observations):\n",
    "    self.sess.run(update_baseline_op, feed_dict={\n",
    "                sinput_placeholder : observations,\n",
    "                baseline_target_placeholder : returns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_paths(sess, env, num_traj,placeholder, num_episodes = None):\n",
    "    paths = []\n",
    "    for i in range(num_traj):\n",
    "        state = env.reset()\n",
    "        states, actions, rewards = [], [], []\n",
    "        #print(max_ep_len)\n",
    "        for step in range(max_ep_len):\n",
    "            states.append(state)\n",
    "            action = sess.run(exploit_action, feed_dict={placeholder : states[-1][None]})[0]\n",
    "            #print(action)\n",
    "            state, reward, done, info = env.step(action)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            #if (done):\n",
    "             #   break\n",
    "\n",
    "        path = {\"observation\" : np.array(states),\n",
    "                            \"reward\" : np.array(rewards),\n",
    "                            \"action\" : np.array(actions)}\n",
    "        paths.append(path)\n",
    "    #print(paths)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_returns(paths):\n",
    "    all_returns = []\n",
    "    for path in paths:\n",
    "        rewards = path[\"reward\"]\n",
    "        returns = []\n",
    "        for i in range(len(rewards)):\n",
    "            path_returns = 0\n",
    "            k = 0\n",
    "            for j in range(i,len(rewards)):\n",
    "                path_returns = path_returns + rewards[j]*(1)**k\n",
    "                k = k+1\n",
    "            returns.append(path_returns)\n",
    "        all_returns.append(returns)\n",
    "    returns = np.concatenate(all_returns)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_trajectories(paths):\n",
    "    trajectories = []\n",
    "    for path in paths:\n",
    "        #print(path)\n",
    "        rewards = path[\"reward\"]\n",
    "        states = path[\"observation\"]\n",
    "        action = path[\"action\"]\n",
    "        SAR = []\n",
    "        #print(len(path))\n",
    "        #print(list(states[0]))\n",
    "        for i in range(len(states)):\n",
    "            #print(list(states[i]) ,[action[i]] , [rewards[i]])\n",
    "            SAR = SAR + list(states[i]) + [action[i]] + [rewards[i]]\n",
    "        trajectories.append(SAR)\n",
    "    \n",
    "    return np.array(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"explore/fully_connected/BiasAdd:0\", shape=(?, 2), dtype=float32)\n",
      "action Tensor(\"multinomial/Multinomial:0\", shape=(?, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "latent_size = 6\n",
    "\n",
    "observation_placeholder = tf.placeholder(tf.float32, shape=(None,observation_dim))\n",
    "if(discrete):\n",
    "    action_placeholder = tf.placeholder(tf.int32, shape=(None))\n",
    "else:\n",
    "    action_placeholder = tf.placeholder(tf.float32, shape=(None,action_dim))\n",
    "\n",
    "sampled_action, logprob = build_policy_explore(observation_placeholder,action_placeholder,action_dim,scope = \"explore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sample_paths() got multiple values for argument 'num_episodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-887-5a8cec0c8b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_traj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobservation_placeholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sample_paths() got multiple values for argument 'num_episodes'"
     ]
    }
   ],
   "source": [
    "paths = sample_paths(sess, env, num_traj,observation_placeholder, num_episodes = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = stack_trajectories(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 60)"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "if discrete:\n",
    "    output_action_PH = tf.placeholder(tf.int32, shape=(None))\n",
    "else:\n",
    "    output_action_PH = tf.placeholder(tf.float32, shape=(None,action_dim))\n",
    "\n",
    "\n",
    "\n",
    "encoder_input_placeholder = tf.placeholder(tf.float32, shape= (num_traj,traj_length))\n",
    "\n",
    "\n",
    "decoder_input_placeholder = tf.placeholder(tf.float32, shape= (1,latent_size))\n",
    "\n",
    "Input_placeholder = tf.placeholder(tf.float32, shape=(None,observation_dim))\n",
    "\n",
    "\n",
    "Encoded = Encoder(encoder_input_placeholder,scope = \"encode2\")\n",
    "# d1 = Decoder1(decoder_input_placeholder,observation_dim*traj_length, scope = \"da\")\n",
    "# d2 = Decoder2(decoder_input_placeholder,traj_length*traj_length, scope = \"db\")\n",
    "# d3 = Decoder3(decoder_input_placeholder,traj_length*action_dim, scope = \"dc\")\n",
    "# d1 = tf.reshape(d1, [observation_dim, traj_length])\n",
    "# d2 = tf.reshape(d2, [traj_length, traj_length])\n",
    "# d3 = tf.reshape(d3, [traj_length, action_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'MatMul_2:0' shape=(?, 2) dtype=float32>,\n",
       " <tf.Tensor 'Placeholder:0' shape=<unknown> dtype=int32>)"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploit_action_logits, output_action_PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploit_action_logits = tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(Input_placeholder,tf.reshape(Decoder1(decoder_input_placeholder,observation_dim*traj_length, scope = \"da\"), [observation_dim, traj_length]))), tf.reshape(Decoder2(decoder_input_placeholder,traj_length*traj_length, scope = \"db\"), [traj_length, traj_length]))),\n",
    "tf.reshape(Decoder3(decoder_input_placeholder,traj_length*action_dim, scope = \"dc\"), [traj_length, action_dim]))\n",
    "exploit_action = tf.multinomial(exploit_action_logits,1)\n",
    "exploit_action = tf.squeeze(exploit_action, axis=1)\n",
    "exploit_logprob = -tf.nn.sparse_softmax_cross_entropy_with_logits(logits = exploit_action_logits, labels = output_action_PH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#exploit_action, exploit_logprob = build_policy_exploit(Input_placeholder, d1, d2, d3,action_dim)\n",
    "\n",
    "advantage_placeholder = tf.placeholder(tf.float32, shape=(None))\n",
    "\n",
    "Policy_loss = -tf.reduce_sum(exploit_logprob * advantage_placeholder)\n",
    "adam_optimizer =  tf.train.AdamOptimizer(0.1)\n",
    "train_op = adam_optimizer.minimize(Policy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Neg_2:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sess.run(Encoded, feed_dict={encoder_input_placeholder : M})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = sess.run(d1, feed_dict={decoder_input_placeholder : Z})\n",
    "d2 = sess.run(d2, feed_dict={decoder_input_placeholder : Z})\n",
    "d3 = sess.run(d3, feed_dict={decoder_input_placeholder : Z})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_paths(sess, env, num_traj, num_episodes = None):\n",
    "    paths = []\n",
    "    for i in range(num_traj):\n",
    "        state = env.reset()\n",
    "        states, actions, rewards = [], [], []\n",
    "        #print(max_ep_len)\n",
    "        for step in range(max_ep_len):\n",
    "            states.append(state)\n",
    "            action = sess.run(exploit_action, feed_dict={Input_placeholder : state[None], decoder_input_placeholder: Z})[0]\n",
    "            #print(action)\n",
    "            state, reward, done, info = env.step(action)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            #if (done):\n",
    "             #   break\n",
    "\n",
    "        path = {\"observation\" : np.array(states),\n",
    "                            \"reward\" : np.array(rewards),\n",
    "                            \"action\" : np.array(actions)}\n",
    "        paths.append(path)\n",
    "    #print(paths)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "paths= sample_paths(sess, env,num_traj )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = np.concatenate([path[\"observation\"] for path in paths])\n",
    "actions = np.concatenate([path[\"action\"] for path in paths])\n",
    "rewards = np.concatenate([path[\"reward\"] for path in paths])\n",
    "returns = get_returns(paths)\n",
    "advantages = np.float32(calculate_advantage(returns, observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "observations = np.concatenate([path[\"observation\"] for path in paths])\n",
    "actions = np.concatenate([path[\"action\"] for path in paths])\n",
    "rewards = np.concatenate([path[\"reward\"] for path in paths])\n",
    "returns = get_returns(paths)\n",
    "advantages = np.float32(calculate_advantage(returns, observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(train_op, feed_dict={\n",
    "                    Input_placeholder : observations,\n",
    "                    output_action_PH : actions,\n",
    "                    advantage_placeholder : returns,\n",
    "                    decoder_input_placeholder: Z})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Layer1 = tf.Variable(Decoder1(decoder_input_placeholder,100, scope = \"da\"))\n",
    "Layer2 = tf.Variable(Decoder2(decoder_input_placeholder,100, scope = \"db\"))\n",
    "Layer3 = tf.Variable(Decoder3(decoder_input_placeholder,action_dim, scope = \"dc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer1 = tf.Variable(np.random.rand(100,100),dtype = tf.float32)\n",
    "Layer2 = tf.Variable(np.random.rand(100,100),dtype = tf.float32)\n",
    "Layer3 = tf.Variable(np.random.rand(100,100),dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-483-bfbb5dda065a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md1_PH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md2_PH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0md3_PH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'shape'"
     ]
    }
   ],
   "source": [
    "d1_PH = tf.placeholder(tf.float32, shape= (100,100))\n",
    "d2_PH = tf.placeholder(tf.float32, shape= (100,100))\n",
    "d3_PH = tf.placeholder(tf.float32, shape= (100, action_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_2:0\", shape=(100, 60), dtype=float32)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'explore/dense/kernel:0' shape=(4, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'explore/dense/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'explore/dense_1/kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'explore/dense_1/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'explore/fully_connected/weights:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'explore/fully_connected/biases:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'encode2/dense/kernel:0' shape=(60, 6) dtype=float32_ref>,\n",
       " <tf.Variable 'encode2/dense/bias:0' shape=(6,) dtype=float32_ref>,\n",
       " <tf.Variable 'encode2/dense_1/kernel:0' shape=(6, 6) dtype=float32_ref>,\n",
       " <tf.Variable 'encode2/dense_1/bias:0' shape=(6,) dtype=float32_ref>,\n",
       " <tf.Variable 'encode2/fully_connected/weights:0' shape=(6, 6) dtype=float32_ref>,\n",
       " <tf.Variable 'encode2/fully_connected/biases:0' shape=(6,) dtype=float32_ref>,\n",
       " <tf.Variable 'da/dense/kernel:0' shape=(6, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'da/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'da/dense_1/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'da/dense_1/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'da/fully_connected/weights:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'da/fully_connected/biases:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'db/dense/kernel:0' shape=(6, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'db/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'db/dense_1/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'db/dense_1/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'db/fully_connected/weights:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'db/fully_connected/biases:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'dc/dense/kernel:0' shape=(6, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'dc/dense/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'dc/dense_1/kernel:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'dc/dense_1/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'dc/fully_connected/weights:0' shape=(2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'dc/fully_connected/biases:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'dc/dense/kernel:0' shape=(6, 2) dtype=float32_ref>, <tf.Variable 'dc/dense/bias:0' shape=(2,) dtype=float32_ref>, <tf.Variable 'dc/dense_1/kernel:0' shape=(2, 2) dtype=float32_ref>, <tf.Variable 'dc/dense_1/bias:0' shape=(2,) dtype=float32_ref>, <tf.Variable 'dc/fully_connected/weights:0' shape=(2, 2) dtype=float32_ref>, <tf.Variable 'dc/fully_connected/biases:0' shape=(2,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "g_vars = [var for var in tvars if 'dc' in var.name]\n",
    "print(g_vars)\n",
    "#var = [ <tf.Variable 'encode2/dense/bias:0' shape=(6,) dtype=float32_ref>]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"Variable:0\", shape=(100, 100), dtype=float32_ref) must be from the same graph as Tensor(\"Placeholder_4:0\", shape=(100, 100), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-495-718da2971332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput_placeholder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLayer1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLayer3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2039\u001b[0m       \u001b[0mare\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m   \"\"\"\n\u001b[0;32m-> 2041\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2042\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0madjoint_a\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only one of transpose_a and adjoint_a can be True.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5769\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5770\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5771\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5772\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   5428\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5429\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5430\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5431\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   5364\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5365\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" % (item,\n\u001b[0;32m-> 5366\u001b[0;31m                                                                 original_item))\n\u001b[0m\u001b[1;32m   5367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor(\"Variable:0\", shape=(100, 100), dtype=float32_ref) must be from the same graph as Tensor(\"Placeholder_4:0\", shape=(100, 100), dtype=float32)."
     ]
    }
   ],
   "source": [
    "baseline = tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(Input_placeholder,Layer1)), Layer2)),Layer3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_target_placeholder = tf.placeholder(tf.float32, shape= None)\n",
    "baseline_loss = tf.losses.mean_squared_error(baseline_target_placeholder,baseline,scope = 'baseline_loss')\n",
    "baseline_optimizer =  tf.train.AdamOptimizer(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_baseline_op = baseline_optimizer.minimize(baseline_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Placeholder' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_1' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_2' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_3' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_4' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_5' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_6' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_7' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_8' type=Placeholder>]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in tf.get_default_graph().get_operations() if \"Placeholder\" in x.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample T Trajectories\n",
    "num_traj = 100\n",
    "num_batches = 20\n",
    "\n",
    "# add place holders\n",
    "observation_placeholder = tf.placeholder(tf.float32, shape=(None,observation_dim))\n",
    "if(discreet):\n",
    "    action_placeholder = tf.placeholder(tf.int32, shape=(None))\n",
    "else:\n",
    "    action_placeholder = tf.placeholder(tf.float32, shape=(None,action_dim))\n",
    "\n",
    "# build policy\n",
    "sampled_action, logprob = build_policy_explore(observation_placeholder,action_placeholder,action_dim)\n",
    "Encoded = Encoder(encoder_input_placeholder)\n",
    "Layer1,Layer2,Layer3 = Decoder(decoder_input_placeholder,d1_out_dim,d2_out_dim,d3_out_dim)\n",
    "exploit_action, exploit_logprob = build_policy_exploit(Input_placeholder, d1_PH, d2_PH, d3_PH,action_dim)\n",
    "\n",
    "\n",
    "# loss op\n",
    "Policy_loss = -tf.reduce_sum(exploit_logprob * advantage_placeholder)\n",
    "adam_optimizer =  tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = adam_optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "#baseline\n",
    "baseline = tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(input_placeholder,d1)), d2)),d3))\n",
    "baseline_target_placeholder = tf.placeholder(tf.float32, shape= None)\n",
    "baseline_loss = tf.losses.mean_squared_error(baseline_target_placeholder,baseline,scope = scope)\n",
    "baseline_optimizer =  tf.train.AdamOptimizer(learning_rate)\n",
    "update_baseline_op = baseline_optimizer.minimize(loss)\n",
    "\n",
    "    \n",
    "# Tensorflow session\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for t in range(num_batches):\n",
    "    # sample paths\n",
    "    paths = sample_paths(sess, env, num_traj, num_episodes = None):\n",
    "\n",
    "    # form trajectory matrix\n",
    "    M = stack_trajectories(paths)\n",
    "    \n",
    "    # encode\n",
    "    Z = sess.run(Encoded, feed_dict={encoder_input_placeholder : M})\n",
    "    \n",
    "    # decode\n",
    "    d1 = tf.Variable(sess.run(Layer1, feed_dict={decoder_input_placeholder : Z}))\n",
    "    d2 = tf.Variable(sess.run(Layer1, feed_dict={decoder_input_placeholder : Z}))\n",
    "    d3 = tf.Variable(sess.run(Layer1, feed_dict={decoder_input_placeholder : Z}))\n",
    "    \n",
    "    scores_eval = []\n",
    "    for t in range(10):\n",
    "        paths, total_rewards = sample_paths(sess, env, num_traj):\n",
    "        scores_eval = scores_eval + total_rewards\n",
    "        observations = np.concatenate([path[\"observation\"] for path in paths])\n",
    "        actions = np.concatenate([path[\"action\"] for path in paths])\n",
    "        rewards = np.concatenate([path[\"reward\"] for path in paths])\n",
    "        returns = get_returns(paths)\n",
    "        advantages = calculate_advantage(returns, observations)\n",
    "        #update baseline\n",
    "        update_baseline(returns, observations)\n",
    "        \n",
    "        sess.run(train_op, feed_dict={\n",
    "                    observation_placeholder : observations,\n",
    "                    d1_H : d1,\n",
    "                    d2_H : d2,\n",
    "                    d3_H : d3,\n",
    "                    action_placeholder : actions,\n",
    "                    advantage_placeholder : advantages})\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "logprob = build_policy_explore(observation_placeholder,action_placeholder,action_dim)\n",
    "Policy_loss = -tf.reduce_sum(logprob * advantage_placeholder)\n",
    "adam_optimizer =  tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = adam_optimizer.minimize(loss)\n",
    "\n",
    "#baseline\n",
    "baseline = tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(input_placeholder,d1)), d2)),d3))\n",
    "baseline_target_placeholder = tf.placeholder(tf.float32, shape= None)\n",
    "baseline_loss = tf.losses.mean_squared_error(baseline_target_placeholder,baseline,scope = scope)\n",
    "baseline_optimizer =  tf.train.AdamOptimizer(learning_rate)\n",
    "update_baseline_op = baseline_optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "# create tf session\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "paths = sample_paths(env, num_traj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
